{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE AUGMENTATION:\n",
    "- a technique that can be used to artificially expand the size of a training set by creating modified data from the existing one.\n",
    "- applyies different *transformations to original images* which results in multiple transformed copies of the same image. \n",
    "- Each copy, however, is different from the other in certain aspects depending on the augmentation techniques we apply like shifting, rotating, flipping, etc.\n",
    "- used to expand the size of our dataset + incorporate a level of variation in the dataset : allows the model to generalize better on unseen data. \n",
    "- USE *Keras ImageDataGenerator*\n",
    "- Used to prevent overfitting & when the sample size is very small.\n",
    "- Also helps to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation in TensorFlow and Keras: To augment images when using TensorFlow or Keras as our DL framework, we can:\n",
    "\n",
    "1. Write our own augmentation pipelines or layers using tf.image.\n",
    "2. Use Keras preprocessing layers\n",
    "3. Use ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the data generators : Setting up data generators in Keras using ImageDataGenerator allows efficient loading and preprocessing of image data for training and validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Keras ImageDataGenerator class :\n",
    "- generates batches of tensor images with real-time DA while your model is still training. ------ [*real-time data augmentation*]\n",
    "- You can apply any random transformation on each training image as it is passed to the model.\n",
    "- saves memory + model becomes robust\n",
    "- Creates a large corpus of similar images without having to worry about collecting new images, which is not feasible in a real-world scenario.\n",
    "\n",
    "- It ensures : model receives new variations of the images at each epoch. But it only returns the transformed images and does not add it to the original corpus of images.[seeing original images multiple times : *Overfiting*]\n",
    "- requires lower memory usage :\n",
    "   * Without using this class : we load all the images at once\n",
    "   * Using it : we load the images in batches which saves a lot of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The ImageDataGenerator() class has 3 methods :\n",
    "- flow(), flow_from_directory() and flow_from_dataframe() to read the images from a big numpy array and folders containing images.\n",
    "* flow_from_directory : allows you to read the images directly from the directory and augment them while the neural network model is learning on the training data.\n",
    "- The directory must be set to the path where your ‘n’ classes of folders are present.\n",
    "- The target_size : size of your input images, every image will be resized to this size.\n",
    "- color_mode: if the image is either black and white or grayscale set “grayscale” or if the image has three color channels, set “rgb”.\n",
    "- batch_size: No. of images to be yielded from the generator per batch.\n",
    "- class_mode: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both    input and the output would probably be the same image, for this case set to “input”.\n",
    "- shuffle: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
    "- seed: Random seed for applying random image augmentation and shuffling the order of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Rotations:\n",
    "- Rotate images :[0 and 360 degrees] -- providing an integer value in the *rotation_range* argument.\n",
    "- So when image is rotated : some pixels will be moved outside the image & leave an empty space that needs to be filled in.\n",
    "- We can fill this in different ways -- like constant value or nearest pixel values, etc. \n",
    "- This is specified in the *fill_mode* argument and the default value is *nearest : simply replaces the empty area with the nearest pixel values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Size of the image: 48x48 pixels\n",
    "pic_size = 48                                                       #Specifies the size of each image (48x48 pixels in this case)\n",
    "\n",
    "\n",
    "# Input path for the images\n",
    "base_path = \"/Users/pratiksha/Documents/Pratiksha/GitHub/Face-expression-recognition-with-Deep-Learning/images\"\n",
    "\n",
    "# number of images to feed into the NN for every batch\n",
    "batch_size = 16     #Specifies the number of images to feed into the neural network for every batch during training and validation.\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,              # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,            # Randomly rotate images in the range (degrees)\n",
    "    width_shift_range=0.2,        # Randomly translate images horizontally\n",
    "    height_shift_range=0.2,       # Randomly translate images vertically\n",
    "    shear_range=0.2,              # Apply shearing transformations\n",
    "    zoom_range=0.2,               # Randomly zoom images\n",
    "    horizontal_flip=True,         # Randomly flip images horizontally\n",
    "    fill_mode='nearest'           # Filling method for points outside boundaries\n",
    ")\n",
    "\n",
    "                            #ImageDataGenerator : it is used to generate a batch of images with some random transformations\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#flow_from_directory() : allows to read the images directly from the directory & augment them while the NN model is learning on the training data.\n",
    "\n",
    "# Creates instances of ImageDataGenerator for training (datagen_train) and validation (datagen_validation). \n",
    "# These generators will handle data augmentation, scaling, and other preprocessing tasks.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(base_path + \"/train\",            # flow_from_directory: Generates batches of augmented/normalized data from image files in the train directory.\n",
    "                                                    target_size=(pic_size,pic_size), # Resizes images to (pic_size, pic_size) pixels.\n",
    "                                                    color_mode=\"grayscale\",           # Converts images to grayscale format.\n",
    "                                                    batch_size=batch_size,            # Number of images per batch to be yielded from the generator.\n",
    "                                                    class_mode='categorical',         # Returns one-hot encoded labels for multi-class classification.\n",
    "                                                    shuffle=True)                     #  Shuffles the order of images after every epoch.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#class_mode: 1.categorical: for multi-class classification problems This means that the target output will be a binary matrix representation of the classes.\n",
    "#            2.binary: for binary classification problems where the labels are 0 or 1. \n",
    "#            3.sparse: for multi-class classification problems where the labels are integers.useful when the number of classes is large.\n",
    "#            4.input: for autoencoders. It returns the input unchanged.\n",
    "#            5.none: if you don't want any labels returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In above and below code we did: base + \"train\" and base + \"validation\" because: our your directory structure might look something like this:\n",
    "/dataset\n",
    "    /train\n",
    "        /class1\n",
    "        /class2\n",
    "        ...\n",
    "    /validation\n",
    "        /class1\n",
    "        /class2\n",
    "        ...\n",
    "\n",
    "* base_path: This is the root path pointing to the parent directory of train\n",
    "* train\": This specifies the subdirectory within base_path that contains the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(base_path + \"/validation\", # fetches batches of validation data from the validation directory.\n",
    "                                                    target_size=(pic_size,pic_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n",
    "# Training Data:   Use shuffle = True to ensure the data is randomized and to help the model generalize better.\n",
    "# Validation Data: Use shuffle = False to maintain a consistent evaluation set and ensure that the validation metrics are reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed class weights: {0: 1.031125898894494, 1: 9.443315858453474, 2: 1.0034817729187702, 3: 0.5747188322565207, 4: 0.8264322991340254, 5: 0.8337962159347335, 6: 1.2846445286382884}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights for the training data\n",
    "classes = train_generator.classes  # Extract class indices from the train generator\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(classes), y=classes)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(\"Computed class weights:\", class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE :\n",
    "There are various image augmentation techniques used:\n",
    "1. Geometric transformations : rotation,randomly flip,crop or translate images.\n",
    "2. Color space transformations : change RGB color channels and intensity of any color\n",
    "3. Kernel filters : sharpen or blur an image\n",
    "4. Random erasing: delete a part of the initial image\n",
    "5. Mixing images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep learning models are trained by being fed with batches of data. Keras has a very useful class to automatically feed data from a directory: ImageDataGenerator.\n",
    "\n",
    "- It can also perform data augmentation while getting the images (randomly rotating the image, zooming, etc.). This method is often used as a way to artificially get more data when the dataset has a small size.\n",
    "\n",
    "- The function flow_from_directory() specifies how the generator should import the images (path, image size, colors, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Found 28821 images belonging to 7 classes: indicates that in the training dataset (base_path + \"train\"), there are a total of 28,821 images distributed among 7 classes.\n",
    "* Found 7066 images belonging to 7 classes: Similarly, in your validation dataset (base_path + \"validation\"), there are 7,066 images also distributed among the same 7 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initial Image Checking: Earlier, we used a loop to display a subset of images (specifically, the first 5 images) from each expression category (angry, disgust, fear, happy, neutral, sad, surprise) in the training data. This was likely done to visually inspect the data and ensure that images are loaded correctly and represent different facial expressions.\n",
    "\n",
    "2. Setting up Data Generators: After verifying the data, we proceeded to set up 'ImageDataGenerator' instances for both training and validation datasets. These generators will be used to feed batches of images into your neural network during the training process.\n",
    "\n",
    "3. Batch Size: We specified a batch_size of 128 when setting up the train_generator and validation_generator. This means that during training, the neural network will process 128 images at a time (or as many as can fit into memory for the hardware configuration). This batch size is a common parameter in deep learning training and affects how many images are processed before updating the model's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTIONS:\n",
    "1. USE of 'train_generator' & 'validation_generator' : \n",
    "- Instances of ImageDataGenerator from Keras that handle data preprocessing and augmentation (if specified). \n",
    "- They generate batches of images and their corresponding labels directly from directories of images, allowing you to work with large datasets that don't fit into memory.\n",
    "- 'train_generator' : used during the training phase of your neural network. It provides batches of images to the model, allowing it to update its weights based on the gradients computed from these batches.\n",
    "- validation_generator : used to evaluate the model's performance on a separate set of data that the model hasn't seen during training. It helps monitor the model's generalization ability and prevents overfitting.\n",
    "\n",
    "2. BATCH SIZE:\n",
    "- Batch size refers to the number of samples (images, in this case) that the model processes at a time before updating the weights.\n",
    "When you set batch_size=128, the model will process 128 images in each iteration (batch) during training.\n",
    "Benefits:\n",
    "\n",
    "* Efficiency: Processing data in batches is more memory efficient. Instead of loading all images into memory at once, which may not be feasible for large datasets, batches allow you to work with manageable chunks.\n",
    "* Gradient Descent: Batch processing allows for more stable gradient descent updates. It computes gradients based on the average loss across the batch, providing smoother convergence towards the optimal weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "- https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
    "- https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/\n",
    "- https://neptune.ai/blog/data-augmentation-in-python#:~:text=Data%20augmentation%20is%20a%20technique,data%20from%20the%20existing%20one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
