{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE AUGMENTATION:\n",
    "- technique of applying different *transformations to original images* which results in multiple transformed copies of the same image. \n",
    "- Each copy, however, is different from the other in certain aspects depending on the augmentation techniques we apply like shifting, rotating, flipping, etc.\n",
    "- used to expand the size of our dataset + incorporate a level of variation in the dataset : allows the model to generalize better on unseen data. \n",
    "- USE *Keras ImageDataGenerator*\n",
    "\n",
    "### Keras ImageDataGenerator class :\n",
    "- lets you augment your images in real-time while your model is still training. ------ [*real-time data augmentation*]\n",
    "- You can apply any random transformation on each training image as it is passed to the model.\n",
    "- saves memory + model becomes robust\n",
    "- Creates a large corpus of similar images without having to worry about collecting new images, which is not feasible in a real-world scenario.\n",
    "\n",
    "- It ensures : model receives new variations of the images at each epoch. But it only returns the transformed images and does not add it to the original corpus of images.[seeing original images multiple times : *Overfiting*]\n",
    "- requires lower memory usage :\n",
    "   * Without using this class : we load all the images at once\n",
    "   * Using it : we load the images in batches which saves a lot of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation:\n",
    "- Rotate images :[0 and 360 degrees] -- providing an integer value in the *rotation_range* argument.\n",
    "- So when image is rotated : some pixels will be moved outside the image & leave an empty space that needs to be filled in.\n",
    "- We can fill this in different ways -- like constant value or nearest pixel values, etc. \n",
    "- This is specified in the *fill_mode* argument and the default value is *nearest : simply replaces the empty area with the nearest pixel values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Input path for the images\n",
    "base_path = \"/Users/pratiksha/Documents/Pratiksha/Documents/GitHub/GitHub/Face-expression-recognition-with-Deep-Learning/images/\"\n",
    "# Size of the image: 48x48 pixels\n",
    "pic_size = 48\n",
    "\n",
    "# number of images to feed into the NN for every batch\n",
    "batch_size = 128\n",
    "\n",
    "datagen_train = ImageDataGenerator() #ImageDataGenerator : it is used to generate a batch of images with some random transformations\n",
    "datagen_validation = ImageDataGenerator() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
