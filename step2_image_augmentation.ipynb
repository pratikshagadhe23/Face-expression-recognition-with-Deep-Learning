{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE AUGMENTATION:\n",
    "- technique of applying different *transformations to original images* which results in multiple transformed copies of the same image. \n",
    "- Each copy, however, is different from the other in certain aspects depending on the augmentation techniques we apply like shifting, rotating, flipping, etc.\n",
    "- used to expand the size of our dataset + incorporate a level of variation in the dataset : allows the model to generalize better on unseen data. \n",
    "- USE *Keras ImageDataGenerator*\n",
    "\n",
    "### Keras ImageDataGenerator class :\n",
    "- lets you augment your images in real-time while your model is still training. ------ [*real-time data augmentation*]\n",
    "- You can apply any random transformation on each training image as it is passed to the model.\n",
    "- saves memory + model becomes robust\n",
    "- Creates a large corpus of similar images without having to worry about collecting new images, which is not feasible in a real-world scenario.\n",
    "\n",
    "- It ensures : model receives new variations of the images at each epoch. But it only returns the transformed images and does not add it to the original corpus of images.[seeing original images multiple times : *Overfiting*]\n",
    "- requires lower memory usage :\n",
    "   * Without using this class : we load all the images at once\n",
    "   * Using it : we load the images in batches which saves a lot of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The ImageDataGenerator() class has 3 methods :\n",
    "- flow(), flow_from_directory() and flow_from_dataframe() to read the images from a big numpy array and folders containing images.\n",
    "* flow_from_directory : allows you to read the images directly from the directory and augment them while the neural network model is learning on the training data.\n",
    "- The directory must be set to the path where your ‘n’ classes of folders are present.\n",
    "- The target_size : size of your input images, every image will be resized to this size.\n",
    "- color_mode: if the image is either black and white or grayscale set “grayscale” or if the image has three color channels, set “rgb”.\n",
    "- batch_size: No. of images to be yielded from the generator per batch.\n",
    "- class_mode: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both    input and the output would probably be the same image, for this case set to “input”.\n",
    "- shuffle: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
    "- seed: Random seed for applying random image augmentation and shuffling the order of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation:\n",
    "- Rotate images :[0 and 360 degrees] -- providing an integer value in the *rotation_range* argument.\n",
    "- So when image is rotated : some pixels will be moved outside the image & leave an empty space that needs to be filled in.\n",
    "- We can fill this in different ways -- like constant value or nearest pixel values, etc. \n",
    "- This is specified in the *fill_mode* argument and the default value is *nearest : simply replaces the empty area with the nearest pixel values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Input path for the images\n",
    "base_path = \"/Users/pratiksha/Documents/Pratiksha/Documents/GitHub/GitHub/Face-expression-recognition-with-Deep-Learning/images/\"\n",
    "# Size of the image: 48x48 pixels\n",
    "pic_size = 48\n",
    "\n",
    "# number of images to feed into the NN for every batch\n",
    "batch_size = 128\n",
    "\n",
    "datagen_train = ImageDataGenerator() #ImageDataGenerator : it is used to generate a batch of images with some random transformations\n",
    "datagen_validation = ImageDataGenerator() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#flow_from_directory() : allows to read the images directly from the directory & augment them while the NN model is learning on the training data.\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(directory = base_path + \"train\",\n",
    "                                                    target_size = (pic_size,pic_size), #size of i/p images -- every image will be resized to this size.\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    batch_size= batch_size,\n",
    "                                                    class_mode='categorical', \n",
    "                                                    shuffle = True,   #shuffle : shuffle the order of the image                                               \n",
    ")\n",
    "#class_mode: 1.categorical: for multi-class classification problems This means that the target output will be a binary matrix representation of the classes.\n",
    "#            2.binary: for binary classification problems where the labels are 0 or 1. \n",
    "#            3.sparse: for multi-class classification problems where the labels are integers.useful when the number of classes is large.\n",
    "#            4.input: for autoencoders. It returns the input unchanged.\n",
    "#            5.none: if you don't want any labels returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In above and below code we did: base + \"train\" and base + \"validation\" because: our your directory structure might look something like this:\n",
    "/dataset\n",
    "    /train\n",
    "        /class1\n",
    "        /class2\n",
    "        ...\n",
    "    /validation\n",
    "        /class1\n",
    "        /class2\n",
    "        ...\n",
    "\n",
    "* base_path: This is the root path pointing to the parent directory of train\n",
    "* train\": This specifies the subdirectory within base_path that contains the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen_validation.flow_from_directory(directory = base_path + \"validation\",\n",
    "                                                               target_size = (pic_size,pic_size), #size of i/p images -- every image will be resized to this size.\n",
    "                                                               color_mode = \"grayscale\",\n",
    "                                                               batch_size= batch_size,\n",
    "                                                               class_mode='categorical', \n",
    "                                                               shuffle = False,)\n",
    "\n",
    "# Training Data:   Use shuffle = True to ensure the data is randomized and to help the model generalize better.\n",
    "# Validation Data: Use shuffle = False to maintain a consistent evaluation set and ensure that the validation metrics are reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "- https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
    "- https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
