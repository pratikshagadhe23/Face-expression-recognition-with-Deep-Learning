{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE AUGMENTATION:\n",
    "- technique of applying different *transformations to original images* which results in multiple transformed copies of the same image. \n",
    "- Each copy, however, is different from the other in certain aspects depending on the augmentation techniques we apply like shifting, rotating, flipping, etc.\n",
    "- used to expand the size of our dataset + incorporate a level of variation in the dataset : allows the model to generalize better on unseen data. \n",
    "- USE *Keras ImageDataGenerator*\n",
    "\n",
    "### Keras ImageDataGenerator class :\n",
    "- lets you augment your images in real-time while your model is still training. ------ [*real-time data augmentation*]\n",
    "- You can apply any random transformation on each training image as it is passed to the model.\n",
    "- saves memory + model becomes robust\n",
    "- Creates a large corpus of similar images without having to worry about collecting new images, which is not feasible in a real-world scenario.\n",
    "\n",
    "- It ensures : model receives new variations of the images at each epoch. But it only returns the transformed images and does not add it to the original corpus of images.[seeing original images multiple times : *Overfiting*]\n",
    "- requires lower memory usage :\n",
    "   * Without using this class : we load all the images at once\n",
    "   * Using it : we load the images in batches which saves a lot of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation:\n",
    "- Rotate images :[0 and 360 degrees] -- providing an integer value in the *rotation_range* argument.\n",
    "- So when image is rotated : some pixels will be moved outside the image & leave an empty space that needs to be filled in.\n",
    "- We can fill this in different ways -- like constant value or nearest pixel values, etc. \n",
    "- This is specified in the *fill_mode* argument and the default value is *nearest : simply replaces the empty area with the nearest pixel values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Input path for the images\n",
    "base_path = \"/Users/pratiksha/Documents/Pratiksha/Documents/GitHub/GitHub/Face-expression-recognition-with-Deep-Learning/images/\"\n",
    "# Size of the image: 48x48 pixels\n",
    "pic_size = 48\n",
    "\n",
    "# number of images to feed into the NN for every batch\n",
    "batch_size = 128\n",
    "\n",
    "datagen_train = ImageDataGenerator() #ImageDataGenerator : it is used to generate a batch of images with some random transformations\n",
    "datagen_validation = ImageDataGenerator() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#flow_from_directory() : allows to read the images directly from the directory & augment them while the NN model is learning on the training data.\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(directory = base_path + \"train\",\n",
    "                                                    target_size = (pic_size,pic_size), #size of i/p images -- every image will be resized to this size.\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    batch_size= batch_size,\n",
    "                                                    class_mode='categorical', \n",
    "                                                    shuffle = True,   #shuffle : shuffle the order of the image                                               \n",
    ")\n",
    "#class_mode: 1.categorical: for multi-class classification problems This means that the target output will be a binary matrix representation of the classes.\n",
    "#            2.binary: for binary classification problems where the labels are 0 or 1. \n",
    "#            3.sparse: for multi-class classification problems where the labels are integers.useful when the number of classes is large.\n",
    "#            4.input: for autoencoders. It returns the input unchanged.\n",
    "#            5.none: if you don't want any labels returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In above and below code we did: base + \"train\" and base + \"validation\" because: our your directory structure might look something like this:\n",
    "/dataset\n",
    "    /train\n",
    "        /class1\n",
    "        /class2\n",
    "        ...\n",
    "    /validation\n",
    "        /class1\n",
    "        /class2\n",
    "        ...\n",
    "\n",
    "* base_path: This is the root path pointing to the parent directory of train\n",
    "* train\": This specifies the subdirectory within base_path that contains the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generrator = datagen_validation.flow_from_directory(directory = base_path + \"validation\",\n",
    "                                                               target_size = (pic_size,pic_size), #size of i/p images -- every image will be resized to this size.\n",
    "                                                               color_mode = \"grayscale\",\n",
    "                                                               batch_size= batch_size,\n",
    "                                                               class_mode='categorical', \n",
    "                                                               shuffle = False,)\n",
    "\n",
    "# Training Data:   Use shuffle = True to ensure the data is randomized and to help the model generalize better.\n",
    "# Validation Data: Use shuffle = False to maintain a consistent evaluation set and ensure that the validation metrics are reliable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
